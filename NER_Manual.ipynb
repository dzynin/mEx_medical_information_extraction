{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Named Entity Recognition\n",
    "## Setup:\n",
    "1. Download the **NER** Model and place it in the **Resources** Folder.\n",
    "2. Create a Python virtual environment *(use: Pyenv, miniConda, etc..)*\n",
    "3. Activate VirtualEnv.\n",
    "4. Install needed python libraries *(python -m pip install -r requierments_ner.txt)*\n",
    "5. Now you'll have an isolated sandbox to experiment around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prediction\n",
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from flair.data import Sentence, Token\n",
    "from flair.models import SequenceTagger\n",
    "import spacy\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings, FlairEmbeddings, TransformerWordEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the NER Model:<br />\n",
    "**model=** *PATH_TO_NER_MODEL* *(.pt file)* <br />\n",
    "Availabe under: LINK TO MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-30 01:41:01,941 loading file Resources/named_entity_recognition_mex_model(custom_flair_embeddings).pt\n"
     ]
    }
   ],
   "source": [
    "NerTagger: SequenceTagger = SequenceTagger.load(model='Resources/named_entity_recognition_mex_model(custom_flair_embeddings).pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some file with text or some string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_sentence: str = \"\"\"Insgesamt gutes Befinden, keine Kraempfe, gute Diurese.\n",
    "RR gut eingestellt, weiter sehr gute Nierenfunktion. Leberwerte ruecklaeufig. Keine Oedeme.\n",
    "Im Sono kein Stau.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: de_core_news_sm==2.3.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz#egg=de_core_news_sm==2.3.0 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (2.3.0)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from de_core_news_sm==2.3.0) (2.3.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.53.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.19.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.9.6)\n",
      "Requirement already satisfied: setuptools in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.7.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.25.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.11.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Spacy default model for the desired language<br />\n",
    "Note: install the model before hand *(python -m spacy download **MODEL_NAME**)*<br />\n",
    "Model-list: https://spacy.io/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will apply Tokenization and sentence splitting on the given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(input_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring the data into the prediction format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentences: list = []\n",
    "for sent in doc.sents:\n",
    "    tmpSent: Sentence = Sentence()\n",
    "    for token in sent:\n",
    "        tmpSent.add_token(Token(token.text))\n",
    "    sentences.append(tmpSent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the results and predict each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for sent in sentences:\n",
    "    NerTagger.predict(sent)\n",
    "\n",
    "first_sentence: Sentence = sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results:\n",
    "String Embedded option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insgesamt gutes <B-State_of_health> Befinden <I-State_of_health> , keine Kraempfe <B-Medical_condition> , gute <B-State_of_health> Diurese <B-Process> .\n"
     ]
    }
   ],
   "source": [
    "print(first_sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotated Spans option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [2,3]: \"gutes Befinden\"   [− Labels: State_of_health (0.9802)]\n",
      "Span [6]: \"Kraempfe\"   [− Labels: Medical_condition (0.9969)]\n",
      "Span [8]: \"gute\"   [− Labels: State_of_health (0.9964)]\n",
      "Span [9]: \"Diurese\"   [− Labels: Process (0.999)]\n"
     ]
    }
   ],
   "source": [
    "for entity in first_sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary Format option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Insgesamt gutes Befinden , keine Kraempfe , gute Diurese .', 'labels': [], 'entities': [{'text': 'gutes Befinden', 'start_pos': None, 'end_pos': None, 'labels': [State_of_health (0.9802)]}, {'text': 'Kraempfe', 'start_pos': None, 'end_pos': None, 'labels': [Medical_condition (0.9969)]}, {'text': 'gute', 'start_pos': None, 'end_pos': None, 'labels': [State_of_health (0.9964)]}, {'text': 'Diurese', 'start_pos': None, 'end_pos': None, 'labels': [Process (0.999)]}]}\n"
     ]
    }
   ],
   "source": [
    "print(first_sentence.to_dict(tag_type='ner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Format option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insgesamt O 0.6336771249771118\n",
      "gutes B-State_of_health 0.9609906077384949\n",
      "Befinden I-State_of_health 0.9993923902511597\n",
      ", O 0.9906901121139526\n",
      "keine O 0.9997430443763733\n",
      "Kraempfe B-Medical_condition 0.9969049096107483\n",
      ", O 0.9995402097702026\n",
      "gute B-State_of_health 0.9963962435722351\n",
      "Diurese B-Process 0.998982846736908\n",
      ". O 0.9842742085456848\n",
      "RR B-Process 0.9997145533561707\n",
      "gut B-State_of_health 0.9910326600074768\n",
      "eingestellt I-State_of_health 0.999576985836029\n",
      ", O 0.998110294342041\n",
      "weiter O 0.6509582996368408\n",
      "sehr B-State_of_health 0.6795549392700195\n",
      "gute I-State_of_health 0.9824131727218628\n",
      "Nierenfunktion B-Body_part 0.9956809282302856\n",
      ". O 0.9991376399993896\n"
     ]
    }
   ],
   "source": [
    "for token in first_sentence.tokens:\n",
    "    print(token.text, token.get_tag('ner').value, token.get_tag('ner').score)\n",
    "\n",
    "for token in sentences[1].tokens:\n",
    "    print(token.text, token.get_tag('ner').value, token.get_tag('ner').score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training\n",
    "### Prepare / Read-in Data:<br />\n",
    "Data should follow the [CoNLL-U](https://universaldependencies.org/format.html) Format,<br />\n",
    "and the NER should be labeled using the [IOB](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) Format.<br />\n",
    "Data Example: <br />\n",
    "* Insgesamt O\n",
    "* gutes B-State_of_health\n",
    "* Befinden I-State_of_health\n",
    "* , O\n",
    "* keine O\n",
    "* Kraempfe B-Medical_condition\n",
    "* , O\n",
    "* gute B-State_of_health\n",
    "* Diurese B-Process\n",
    "* . O <br />\n",
    "**EMPTY LINE TO INDICATE NEW SENTENCE ON NEW LINE** <br />\n",
    "* RR B-Process\n",
    "* gut B-State_of_health\n",
    "* eingestellt I-State_of_health\n",
    "* , O\n",
    "* weiter O\n",
    "* sehr B-State_of_health\n",
    "* gute I-State_of_health\n",
    "* Nierenfunktion B-Body_part\n",
    "* . O <br />\n",
    "\n",
    "Split The Data into Train/Dev/Test Sets.<br />\n",
    "Define the columns of your data, it might include other Features such as POS-Tags or whatever fits your use-case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Initialize Embeddings** (Either use Default Models found under [Flair-Models](https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/FLAIR_EMBEDDINGS.md)\n",
    "or train / fine-tune your own model and give the path to the model file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# 1. init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus('PATH_TO_YOUR_DATA_FILE', columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='dev.txt',\n",
    "                              column_delimiter='\\t',\n",
    "                              document_separator_token='\\n')\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "        WordEmbeddings('de'),\n",
    "        FlairEmbeddings(\"de-forward\"),\n",
    "        FlairEmbeddings(\"de-backward\"),\n",
    "        PooledFlairEmbeddings('german-forward'),\n",
    "        PooledFlairEmbeddings('german-backward'),\n",
    "]\n",
    "\n",
    "# Stack the embeddings\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True,\n",
    "                                        locked_dropout=0.3)\n",
    "\n",
    "# initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus, use_tensorboard=False)\n",
    "\n",
    "# Start Training\n",
    "trainer.train('PATH_TO_SAVE_NEW_MODEL_UNDER',\n",
    "              train_with_dev=False,\n",
    "              max_epochs=25,\n",
    "              mini_batch_size=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# 1. init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus('PATH_TO_YOUR_DATA_FILE', columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='dev.txt',\n",
    "                              column_delimiter='\\t',\n",
    "                              document_separator_token='\\n')\n",
    "\n",
    "# 2. load the pre-trained sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "tagger: SequenceTagger = SequenceTagger.load(\"PATH_TO_EXISTING_MODEL\")\n",
    "\n",
    "# 3. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 4. fine-tune on the target corpus\n",
    "trainer.train(\n",
    "    base_path=\"PATH_TO_SAVE_NEW_MODEL_UNDER\",\n",
    "    train_with_dev=False,\n",
    "    max_epochs=200,\n",
    "    learning_rate=0.1,\n",
    "    mini_batch_size=32\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
