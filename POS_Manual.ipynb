{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Medical Part-Of-Speech Tagger\n",
    "## Setup\n",
    "1. Download the [**POS**](https://cloud.dfki.de/owncloud/index.php/s/e7G9deea7eRksCY) Model and place it in the **Resources** Folder.\n",
    "2. Create a Python virtual environment *(use: Pyenv, miniConda, etc..)*\n",
    "3. Activate VirtualEnv.\n",
    "4. Install needed python libraries *(python -m pip install -r requierments_ner.txt)*\n",
    "5. Now you'll have an isolated sandbox to experiment around.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction\n",
    "Import relevant libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ammer/miniconda3/envs/NER/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from flair.data import Sentence, Token\n",
    "from flair.models import SequenceTagger\n",
    "import spacy\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings, FlairEmbeddings, TransformerWordEmbeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start by loading the NER Model:<br />\n",
    "**model=** *PATH_TO_NER_MODEL* *(.pt file)* <br />\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17 16:33:58,991 loading file Resources/part_of_speech_tagger_mex_model(Def_Word_Flair).pt\n"
     ]
    }
   ],
   "source": [
    "POSTagger: SequenceTagger = SequenceTagger.load(model='Resources/part_of_speech_tagger_mex_model(Def_Word_Flair).pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load some file with text or some string"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input_sentence: str = \"\"\"Insgesamt gutes Befinden, keine Kraempfe, gute Diurese.\n",
    "RR gut eingestellt, weiter sehr gute Nierenfunktion. Leberwerte ruecklaeufig. Keine Oedeme.\n",
    "Im Sono kein Stau.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m spacy download de_core_news_sm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load Spacy default model for the desired language<br />\n",
    "Note: install the model before hand *(python -m spacy download **MODEL_NAME**)*<br />\n",
    "Model-list: https://spacy.io/models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will apply Tokenization and sentence splitting on the given text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc = nlp(input_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bring the data into the prediction format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-76ee17d73d53>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0msentences\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mlist\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0msent\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdoc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msents\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mtmpSent\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mSentence\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSentence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msent\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mtmpSent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_token\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mToken\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "sentences: list = []\n",
    "for sent in doc.sents:\n",
    "    tmpSent: Sentence = Sentence()\n",
    "    for token in sent:\n",
    "        tmpSent.add_token(Token(token.text))\n",
    "    sentences.append(tmpSent)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iterate through the results and predict each sentence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-9e4d7bdd9549>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mPOSTagger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mfirst_sentence\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mSentence\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msentences\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    POSTagger.predict(sent)\n",
    "\n",
    "first_sentence: Sentence = sentences[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display Results:\n",
    "String Embedded option"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(first_sentence.to_tagged_string())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Custom Format option"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for token in first_sentence.tokens:\n",
    "    print(token.text, token.get_tag('pos').value, token.get_tag('pos').score)\n",
    "\n",
    "for token in sentences[1].tokens:\n",
    "    print(token.text, token.get_tag('pos').value, token.get_tag('pos').score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}